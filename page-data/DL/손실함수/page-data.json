{"componentChunkName":"component---src-templates-blog-post-js","path":"/DL/손실함수/","result":{"data":{"site":{"siteMetadata":{"title":"DABI_devlog","author":"[DABIN SEO]","siteUrl":"https://Dabinnny.github.io","comment":{"disqusShortName":"","utterances":"Dabinnny/Dabinnny.github.io"},"sponsor":{"buyMeACoffeeId":""}}},"markdownRemark":{"id":"eb699925-ea6b-5579-9e60-88c28de597ee","excerpt":"📈 손실함수 = 비용함수(Cost Function)알아보기 손실함수란? 실제값과 예측값의 차이(오차)를 나타내는 지표로, 손실함수의 값이 최소화 되도록 하는 가중치(weight)와 편향(bias)를 찾는것이 학습 목표   ‘0’에 가까울수록 모델의 정확도가 높은것 손실함수를 쓰는 이유 왜 정확도를 사용하지 않고 loss…","html":"<h1 id=\"-손실함수--비용함수cost-function알아보기\" style=\"position:relative;\"><a href=\"#-%EC%86%90%EC%8B%A4%ED%95%A8%EC%88%98--%EB%B9%84%EC%9A%A9%ED%95%A8%EC%88%98cost-function%EC%95%8C%EC%95%84%EB%B3%B4%EA%B8%B0\" aria-label=\" 손실함수  비용함수cost function알아보기 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>📈 손실함수 = 비용함수(Cost Function)알아보기</h1>\n<br/> \n<h2 id=\"손실함수란\" style=\"position:relative;\"><a href=\"#%EC%86%90%EC%8B%A4%ED%95%A8%EC%88%98%EB%9E%80\" aria-label=\"손실함수란 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>손실함수란?</h2>\n<ul>\n<li>실제값과 예측값의 차이(오차)를 나타내는 지표로, 손실함수의 값이 최소화 되도록 하는 가중치(weight)와 편향(bias)를 찾는것이 학습 목표  </li>\n<li>‘0’에 가까울수록 모델의 정확도가 높은것</li>\n</ul>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">model<span class=\"token punctuation\">.</span><span class=\"token builtin\">compile</span><span class=\"token punctuation\">(</span>optimizer<span class=\"token operator\">=</span><span class=\"token string\">'adam'</span><span class=\"token punctuation\">,</span>\n              loss<span class=\"token operator\">=</span><span class=\"token string\">'sparse_categorical_crossentropy'</span><span class=\"token punctuation\">,</span>\n              metric<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span><span class=\"token string\">'accuracy'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span></code></pre></div>\n<br/> \n<br/> \n<h2 id=\"손실함수를-쓰는-이유\" style=\"position:relative;\"><a href=\"#%EC%86%90%EC%8B%A4%ED%95%A8%EC%88%98%EB%A5%BC-%EC%93%B0%EB%8A%94-%EC%9D%B4%EC%9C%A0\" aria-label=\"손실함수를 쓰는 이유 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>손실함수를 쓰는 이유</h2>\n<p>왜 정확도를 사용하지 않고 loss값을 구할까? 라고 의문이 들 수 있다. 이러한 의문은 ‘미분’이라는 방식과 연관된다.<br>\n신경망 학습에서는 최적의 매개변수 (가중치와 편향) 값을 탐색할 떄 손실 함수의 값을 가능한 작게 하는 매개변수 값을 찾는다.<br>\n이 때 매개변수의 미분을 계산하고, 그 미분 값을 단서로 매개변수의 값을 서서히 갱신하는과정을 반복하게 된다.<br>\n즉, 손실함수는 매개변수의 변화에 연속적으로 변화하지만, 정확도는 매개변수의 변화에 둔감하고, 변화가 있더라도 불연속적으로 변화하기 때문에 미분이 불가능하다.<br>\n미분이 안되면 최적화를 할 수 없어서 정확도가 아닌 손실 함수를 지표를 삼아 학습을 하는 것이다.</p>\n<br/> \n<br/> \n<h2 id=\"1-회귀-모델에서의-손실함수\" style=\"position:relative;\"><a href=\"#1-%ED%9A%8C%EA%B7%80-%EB%AA%A8%EB%8D%B8%EC%97%90%EC%84%9C%EC%9D%98-%EC%86%90%EC%8B%A4%ED%95%A8%EC%88%98\" aria-label=\"1 회귀 모델에서의 손실함수 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>1. 회귀 모델에서의 손실함수</h2>\n<p>회귀 타입에 사용되는 손실함수는 대표적으로 평균 오차 계산법이 있으며, 평균 오차를 계산하는 방식(공식)에 따라 MAE,MSE,RMSE로 구분된다.</p>\n<br/> \n<br/> \n<h3 id=\"1-평균-절대-오차mean-absolute-errormae\" style=\"position:relative;\"><a href=\"#1-%ED%8F%89%EA%B7%A0-%EC%A0%88%EB%8C%80-%EC%98%A4%EC%B0%A8mean-absolute-errormae\" aria-label=\"1 평균 절대 오차mean absolute errormae permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>(1) 평균 절대 오차(Mean Absolute Error,MAE)</h3>\n<br/> \n<div align=\"center\"><img src=\"https://user-images.githubusercontent.com/90162819/161427157-1f77f0b3-9f2f-4d05-aa39-3932517949b3.png\" width=\"300\"> </div> \n<br/> \n<ul>\n<li>예측값과 실제값의 차이에 절대값을 취하고, 그 값들을 전부 더하여 개수로 나누어 평균을 낸 값  </li>\n<li>절대값을 취하기 때문에 음수인지 양수인지 판단할 수 없으며, 아래 그림처럼 최적값에 가까워졌다고 하더라도 이동거리가 일정하기 때문에<br>\n최적값에 수렴하기 어려움</li>\n</ul>\n<div align=\"center\"><img src=\"https://media.vlpt.us/images/yuns_u/post/fb669365-3513-4bee-bf7f-dc0ab4859e45/image.png\" width=\"450\"> </div> \n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">from</span> sklearn<span class=\"token punctuation\">.</span>metrics <span class=\"token keyword\">import</span> mean_absolute_error\nmean_absolute_error<span class=\"token punctuation\">(</span>y_test<span class=\"token punctuation\">,</span> y_pred<span class=\"token punctuation\">)</span></code></pre></div>\n<br/> \n<br/> \n<br/> \n<h3 id=\"2-평균-제곱-오차mean-squared-errermse\" style=\"position:relative;\"><a href=\"#2-%ED%8F%89%EA%B7%A0-%EC%A0%9C%EA%B3%B1-%EC%98%A4%EC%B0%A8mean-squared-errermse\" aria-label=\"2 평균 제곱 오차mean squared errermse permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>(2) 평균 제곱 오차(Mean Squared Errer,MSE)</h3>\n<br/> \n<div align=\"center\"><img src=\"https://user-images.githubusercontent.com/90162819/161427165-3f6eb52e-453c-4465-92d5-ebce24955b13.png\" width=\"300\"> </div> \n<br/> \n<ul>\n<li>가장 많이 쓰이는 손실함수로 예측값과 실제값 사이의 평균을 제곱하여 평균을 낸 값  </li>\n<li>MAE와 달리 최적값에 가까워질 경우 이동거리가 다르게 변화하기 때문에 최적값에 수렴하는데 용이 </li>\n<li>값을 제곱하기 때문에 1 미만의 값은 더 작아지고, 그 이상의 값은 더 커짐(값의 왜곡이 있을 수 있음) </li>\n</ul>\n<br/> \n<div align=\"center\"><img src=\"https://media.vlpt.us/images/yuns_u/post/56ae069c-bb69-4f43-87fe-7412ad61aeb7/image.png\" width=\"450\"> </div> \n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">from</span> sklearn<span class=\"token punctuation\">.</span>metrics <span class=\"token keyword\">import</span> mean_squared_error \nmean_squared_error<span class=\"token punctuation\">(</span>y_test<span class=\"token punctuation\">,</span> y_pred<span class=\"token punctuation\">)</span></code></pre></div>\n<br/> \n<br/> \n<br/> \n<h3 id=\"3-평균-제곱근-오차root-mean-square-errorrmse\" style=\"position:relative;\"><a href=\"#3-%ED%8F%89%EA%B7%A0-%EC%A0%9C%EA%B3%B1%EA%B7%BC-%EC%98%A4%EC%B0%A8root-mean-square-errorrmse\" aria-label=\"3 평균 제곱근 오차root mean square errorrmse permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>(3) 평균 제곱근 오차(Root Mean Square Error,RMSE)</h3>\n<br/> \n<div align=\"center\"><img src=\"https://user-images.githubusercontent.com/90162819/161427172-2863aebd-e559-4492-9403-b41763aabcd7.png\" width=\"400\"> </div> \n<br/> \n<ul>\n<li>MSE에 루트를 씌운 지표로 값을 제곱해서 생기는 왜곡이 줄어들고 오차를 보다 직관적으로 나타냄  </li>\n</ul>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">from</span> sklearn<span class=\"token punctuation\">.</span>metrics <span class=\"token keyword\">import</span> mean_squared_error \nMSE <span class=\"token operator\">=</span> mean_squared_error<span class=\"token punctuation\">(</span>y_test<span class=\"token punctuation\">,</span> y_pred<span class=\"token punctuation\">)</span> \nnp<span class=\"token punctuation\">.</span>sqrt<span class=\"token punctuation\">(</span>MSE<span class=\"token punctuation\">)</span></code></pre></div>\n<br/> \n<br/> \n<br/> \n<h2 id=\"2-분류-모델에서의-손실함수\" style=\"position:relative;\"><a href=\"#2-%EB%B6%84%EB%A5%98-%EB%AA%A8%EB%8D%B8%EC%97%90%EC%84%9C%EC%9D%98-%EC%86%90%EC%8B%A4%ED%95%A8%EC%88%98\" aria-label=\"2 분류 모델에서의 손실함수 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>2. 분류 모델에서의 손실함수</h2>\n<p>cross-entropy 라고 하며 실제 분포 q에 대하여 알지 못하는 상태에서, 모델링을 통하여 구한 분포인 p를 통하여 q를 예측한다. Cross-entropy는 label의 값이 one-hot encoding일 경우에만 사용 가능</p>\n<br/> \n<br/> \n<h3 id=\"1-binary-crossentropy\" style=\"position:relative;\"><a href=\"#1-binary-crossentropy\" aria-label=\"1 binary crossentropy permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>(1) binary crossentropy</h3>\n<div align=\"center\"><img src=\"https://user-images.githubusercontent.com/90162819/161427190-a524d6bf-5b58-4697-9cb1-e3846685125a.png\" width=\"550\"> </div> \n<ul>\n<li>이진 분류일때 사용하는 방식으로 예측값이 0~1 사이의 확률값으로 나옴</li>\n<li>0에 가까울수록, 1에 가까울수록 둘 중 한 클래스에 가깝다는 것</li>\n</ul>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>losses<span class=\"token punctuation\">.</span>BinaryCrossentropy<span class=\"token punctuation\">(</span>from_logits<span class=\"token operator\">=</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">,</span> label_smoothing<span class=\"token operator\">=</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span>\n                                   reduction<span class=\"token operator\">=</span><span class=\"token string\">\"auto\"</span><span class=\"token punctuation\">,</span> name<span class=\"token operator\">=</span><span class=\"token string\">\"binary_crossentropy\"</span><span class=\"token punctuation\">)</span></code></pre></div>\n<br/> \n<br/> \n<h3 id=\"2-categorical-crossentropy\" style=\"position:relative;\"><a href=\"#2-categorical-crossentropy\" aria-label=\"2 categorical crossentropy permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>(2) categorical crossentropy</h3>\n<div align=\"center\"><img src=\"https://user-images.githubusercontent.com/90162819/161427205-a240f226-e299-4469-a459-8c6d965fb32a.png\" width=\"550\"> </div>  \n<ul>\n<li>분류해야 할 클래스가 3개 이상인 경우, one-hot encoding 된 멀티클래스 분류시에 사용</li>\n<li>예측값은 [0.02 0.94 0.02 0.01 0.01]와 같은 식으로 나오기 때문에 여러 class중 가장 적절한 하나의 class를 분류하는 문제에 사용  </li>\n</ul>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>losses<span class=\"token punctuation\">.</span>CategoricalCrossentropy<span class=\"token punctuation\">(</span>from_logits<span class=\"token operator\">=</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">,</span> label_smoothing <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">,</span>  \n                                        reduction<span class=\"token operator\">=</span><span class=\"token string\">\"auto\"</span><span class=\"token punctuation\">,</span> name <span class=\"token operator\">=</span> 'catogorical_crossentropy\"<span class=\"token punctuation\">)</span></code></pre></div>\n<br/> \n<br/> \n<br/> \n<h3 id=\"3-sparse-categorical-crossentropy\" style=\"position:relative;\"><a href=\"#3-sparse-categorical-crossentropy\" aria-label=\"3 sparse categorical crossentropy permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>(3) sparse categorical crossentropy</h3>\n<br/> \n<ul>\n<li>멀티클래스 분류시에 사용하며 one-hot encoding 된 상태일 필요 없이 정수 인코딩 된 상태에서 사용</li>\n<li>라벨이 (1,2,3,4) 이런식으로 정수형태일때 사용</li>\n</ul>\n<br/> \n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>losses<span class=\"token punctuation\">.</span>sparse_categorical_crossentropy<span class=\"token punctuation\">(</span>y_true<span class=\"token punctuation\">,</span> y_pred<span class=\"token punctuation\">,</span> from_logits<span class=\"token operator\">=</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">,</span> axis<span class=\"token operator\">=</span><span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span></code></pre></div>\n<br/> \n<br/> \n<br/> \n<br/> \n<br/> \n<br/> \n<br/> \n<blockquote>\n<p>Reference  </p>\n</blockquote>\n<ul>\n<li><a href=\"https://brunch.co.kr/@mnc/9\">https://brunch.co.kr/@mnc/9</a></li>\n</ul>","frontmatter":{"title":"손실함수(Loss Function) 종류","date":"March 15, 2022"}}},"pageContext":{"slug":"/DL/손실함수/","previous":{"fields":{"slug":"/ETC/miniforge/"},"frontmatter":{"title":"Mac M1 Miniforge,Tensorflow 설치하기"}},"next":{"fields":{"slug":"/ETC/jave/"},"frontmatter":{"title":"Mac M1 Konlpy 설치하기 "}}}},"staticQueryHashes":["3128451518","635777304"]}