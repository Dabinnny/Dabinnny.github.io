{"componentChunkName":"component---src-templates-blog-post-js","path":"/논문뽀개기/StarGANv2/","result":{"data":{"site":{"siteMetadata":{"title":"DABI_devlog","author":"[DABIN SEO]","siteUrl":"https://Dabinnny.github.io","comment":{"disqusShortName":"","utterances":"Dabinnny/Dabinnny.github.io"},"sponsor":{"buyMeACoffeeId":""}}},"markdownRemark":{"id":"d7c8754c-13cf-5770-a7bc-d3d35ace9973","excerpt":"📖 Multi-modal & Multi-domain image-to-image translation 이 글은 ‘StarGAN v2 : Diverse Image Synthesis for Multiple Domains’ 논문을 바탕으로 합니다.\n 1. Introduction 관련 용어 정리    : 이미지의 특징 (ex. 머리색, 성별)  : 각각의 attribute가 가질 수 있는 값  (ex. 검정,금발 / 남성,여성)   : 같은 attribute value…","html":"<h1 id=\"-multi-modal--multi-domain-image-to-image-translation\" style=\"position:relative;\"><a href=\"#-multi-modal--multi-domain-image-to-image-translation\" aria-label=\" multi modal  multi domain image to image translation permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>📖 Multi-modal &#x26; Multi-domain image-to-image translation</h1>\n<br/>  \n<blockquote>\n<p>이 글은 <em>‘StarGAN v2 : Diverse Image Synthesis for Multiple Domains’</em> 논문을 바탕으로 합니다.\n<br/></p>\n</blockquote>\n<h2 id=\"1-introduction\" style=\"position:relative;\"><a href=\"#1-introduction\" aria-label=\"1 introduction permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>1. Introduction</h2>\n<p><strong>관련 용어 정리</strong>  </p>\n<ul>\n<li><code class=\"language-text\">attribute</code> : 이미지의 특징 (ex. 머리색, 성별)</li>\n<li><code class=\"language-text\">attribute value</code> : 각각의 attribute가 가질 수 있는 값  (ex. 검정,금발 / 남성,여성) </li>\n<li><code class=\"language-text\">domain</code> : 같은 attribute value를 가지는 데이터 집합<br/><br/></li>\n</ul>\n<p>기존의 StarGAN은 하나의 모델로 여러 domain의 이미지를 생성할 수 있지만, 변경하고자 하는 domain 갯수 만큼의 모델이 필요했다. 즉, 아래와 같은 한계점이 있다.  </p>\n<p>  <code class=\"language-text\">1) 한정된 domain에 대해서만 변형</code><br>\n<code class=\"language-text\">2) 한번에 한가지 domain에 대해서만 변형</code></p>\n<p>이에 StarGAN v2는 domain label을 domain-specific style code로 변경하여, 다양한 domain에 대한 style transfer가 가능하도록 개선하였다. 이를 위해  ‘mapping network’와 ‘a style encoder’, 이 두가지 모듈을 추가했는데, 이 모듈들은 각각 style code를 추출하고 변환시킨다. 아래는 StarGAN v2 demo이다.  </p>\n<div align=\"center\">\n<img src=\"https://kozistr.tech/cd0ea8d778c9c993eb43f0ffa687ad43/celeba_hq_teaser_video.gif \">\n</div>\n<h2 id=\"2-network-architecture\" style=\"position:relative;\"><a href=\"#2-network-architecture\" aria-label=\"2 network architecture permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>2. Network Architecture</h2>\n<p><span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto;  max-width: 1005px;\">\n      <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 52%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAKCAYAAAC0VX7mAAAACXBIWXMAAAsSAAALEgHS3X78AAACWElEQVQoz0WSy08TYRTF+18Rw8r/xeAOCaAuZUcEWxeCkba40xCkCASjKIlRIk2ABWpLH/bBdPqeaaevefRBf96vJDrJl+/OmZN7zzl3fMPhkGqtxk4kwveTE1zXZTQakU6l2Y/sEo/HGQwGKF4ymWB/d4tE4kqwISPB4skkbw8OSMit3n2K3O12OT4+JhaLYds2fc8jc33NQ/8q6Wx2QvRch1RWZ2E1Ql4rMhp4OP0+ujTam5+nqGmMAJ9SpB6lRNWT0+kQONznzqN57m+8pNezcbsmK3sVphYvmN3U8LotDNfDXF7mamqK6uws3s0NPtXs7PycezMzPFlaolQuwXjM4fkZdx8v8ubbV1HcZzx0eB81mF44EazGyLOxx2BJVBfT0zS2tugrhcrm2vo6D+bm8AcCWJYl9lwcUZlMJOi1WngSgePYgpmT/Jy2IZiL7TiYwo0LryZRuRKBzzAM8vk8hmkiAyd5ZQoawaOPvP5yRPjzEcV6hVyxwfqHIuEjndAnnYJpY2XS1F6sUQ2FqAWDuOUyvrHYU03Dm5v8OD1lIFMuf/8iEA7hD27wPBzmTzZD7CrN6sYOz15tC7YrS9NJ/bxk++kK7/x+dsSdLgv81zAajZLN5biRYDtit1wsUpBNq1ttvtftUC1p6FqWarmAKxF0ej3yoiqj62iVCo7Y96nMWpKTKZYbjcakbrfbk+WUSiXKQlQcdeqGKXhZeE0s4VnNJka9TlEaNkRUs2nhy4lMpSwnJ5PJkEqluBZlqlbZ5vK3327rPJr8b6rOZv9z1WCF69L4L2T6vnGyjr7qAAAAAElFTkSuQmCC&apos;); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"network\" title=\"network\" src=\"/static/d438e0a8be1a474be413b736e94199fd/18c13/network.png\" srcset=\"/static/d438e0a8be1a474be413b736e94199fd/5a46d/network.png 300w,\n/static/d438e0a8be1a474be413b736e94199fd/0a47e/network.png 600w,\n/static/d438e0a8be1a474be413b736e94199fd/18c13/network.png 1005w\" sizes=\"(max-width: 1005px) 100vw, 1005px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\">\n    </span>  <br/></p>\n<p>StarGAN v2는 총 4개의 모듈로 구성된다. </p>\n<blockquote>\n<p>(a) Generator, (b) Mapping network (c) Style encoder와 (d) Discriminator   </p>\n</blockquote>\n<p><br/><strong><span style=\"background-color:#fff5b1\">1) Generator</strong></span></p>\n<p>생성기 Generator는 input image x와 mapping network와 style encoder로 부터 생성된 style code s를 받아 output image G(x,s)를 생성한다. 이때, s를 적용하기 위해 adaptive instance normalization(AdaIN) 방법이 사용된다. </p>\n<blockquote>\n<p>AdaIN 이란?  </p>\n<ul>\n<li>Contents input과 Style input이 주어졌을 때, 간단하게 content input의 mean과 variance를 style input의 mean과 variance와 match되도록 조정해서 Generator에 주입</li>\n</ul>\n</blockquote>\n<p><br/><strong><span style=\"background-color:#fff5b1\">2) Mapping network</strong></span></p>\n<p>latent code z 와 domain y 에 대해서, style code를 생성하는데 이때, 가능한 모든 도메인의 style code를 제공하기 위해 여러 output branch와 함께 MLP로 구성되며, z와 y의 random sample에서 다양한 style codes를 생성한다. 공식은 아래와 같다.</p>\n<p><br/><strong><span style=\"background-color:#fff5b1\">3) Style encoder</strong></span></p>\n<p>image x 와 domain y 에서 style information 을 추출한다. 서로 다른 reference image에 대해서 다양한 s를 생성하고 Generator에서 결과 이미지를 생성할때 사용된다.</p>\n<p><br/><strong><span style=\"background-color:#fff5b1\">4) Discriminator</strong></span></p>\n<p>각 domain y 에 대해 input 이미지가 진짜인지 가짜인지 binary classification을 수행한다. 이때 주어진 이미지가 해당 domain의 이미지로 볼 수 있는지 판별한다.</p>\n<h2 id=\"3-손실함수\" style=\"position:relative;\"><a href=\"#3-%EC%86%90%EC%8B%A4%ED%95%A8%EC%88%98\" aria-label=\"3 손실함수 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>3. 손실함수</h2>\n<p><span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto;  max-width: 510px;\">\n      <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 74%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAPCAIAAABr+ngCAAAACXBIWXMAAAsSAAALEgHS3X78AAACuUlEQVQoz11SyW4cNxDtf8oP5BcMfUfO8XILckxiSHYuTmDIlgL5YBiwYXhTdEkAQbKlBAGkmZFmrB51TzfZTbIX9sKddI1yCVJ4LLwiwO5X9SoK/3wdzm6F840w2QizjfD3V2F5J0C4IXgRXB+CCl7dEHHDxzXxMmgS9S02shk7OrRlTdKaLHmNmqYeh77vuZSClLjruFaSt01dV0PfVRXtuzaUe1HBGi7EKBWtmxUuUlQWhGKU8raiBBU4m8/O8nyl5ICyaygZK/IsqVkZyItIkYUsLlS5UOWlJoC55TnI8154p70dQtBrgE7QHMxNqdalxVG8fftq+9v46e1451785O7i0Ter1w+C915Lb1TQwsrBKmFEb8YeiBWDGTsrR8mKiPeDtrblfFSa1fUqy4VSlJSMMc67LM+bpnXOhf+F98Wfe1FVlKrrVMcbUpbZCmCFQOmSFqipyHJxgbPUwv/VCNkZ+S93WrCTN1GCptdomqBZkk9TfHGNpwWNbz7tAiD44Ky32mvlDYzABKPXACL66PH7H5/8vvXr2x+29zefHmw9fPndq6Pf4LFxGh5JI40zzsMxUAKUUXCprCoaFFWskUI2dUMpG4dRSj2fzz9fLQgpwCiwGuEcF4hSMl/M8zwDLdYawOH5ftTWROsRXGlb0tRlxxnYSxit6opQorTiHa+qCtYjXWWU0fXueZigO5wcRJ8m16fTBPDXLDmdJR/Pk9kS+aBBp3FKqgGydVoZAdlBI3oEaAMS++inneP7O0f3d49/fnayuXv8/S9/7L2beB+kctYFZTwA2jU2KO2hVyHtCK5Lm2AejT2HBmAKINca5Z2Nrz6D7S1v4zjOc1SWhFB6eTnPclAU3Fq0t859OFxEGGFW1VobVlVpmmJcrlbZANH3hBBYlbZtedchlCOE/7Mj/vnB5AsBIDqZ+okuogAAAABJRU5ErkJggg==&apos;); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"loss\" title=\"loss\" src=\"/static/959d18bca079bb23a9b3aa71e066bcfc/0abdd/loss.png\" srcset=\"/static/959d18bca079bb23a9b3aa71e066bcfc/5a46d/loss.png 300w,\n/static/959d18bca079bb23a9b3aa71e066bcfc/0abdd/loss.png 510w\" sizes=\"(max-width: 510px) 100vw, 510px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\">\n    </span> <br/></p>\n<p>StarGAN v2는 총 4개의 손실함수로 구성된다.</p>\n<blockquote>\n<p>x : 원본 이미지<br>\ny : 이미지x의 도메인<br>\ny~: 타깃 도메인<br>\ns~: F<em>y~(z), 타깃 도메인에 대한 스타일 벡터<br>\ns^: E</em>y(x), 이미지 x에서 도메인 y에 대해 추출한 스타일 벡터<br>\nD_y : 도메인 y에 대한 Discriminator</p>\n</blockquote>\n<p><br/><strong>1) Adversalrial loss</strong></p>\n<p>Discriminator를 통한 loss로 GAN에 기반한 standard function이다. Generator는 x,<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mover accent=\"true\"><mi>s</mi><mo stretchy=\"true\">‾</mo></mover></mrow><annotation encoding=\"application/x-tex\">\\overline{s}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.63056em;vertical-align:0em;\"></span><span class=\"mord overline\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.63056em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">s</span></span></span><span style=\"top:-3.55056em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"overline-line\" style=\"border-bottom-width:0.04em;\"></span></span></span></span></span></span></span></span></span>를 input으로 받고 adversarial loss로 학습한다.</p>\n<p><br/><strong>2) Style reconstruction loss</strong></p>\n<p>이미지를 변환할때 사용된 style vector와  변환이미지를 style encoder 입력으로 넣었을때 같은값이 나오는지 확인한다. Generator가 ̃ s~를 더 잘 활용하도록 style reconstruction loss로 학습하고, 하나의 encoder로 여러 domain에 대해 다양한 출력을 뽑아낼 수 있다.</p>\n<p><br/><strong>3) Diversity sensitive loss</strong></p>\n<p>서로 다른 s가 주어졌을때 출력이미지가 실제로 유의미하게 다른 이미지로 변환이 되었는지 확인한다. Generator가 다양한 이미지들을 만들어낼 수 있도록 diversity sensitive loss를 적용해 정규화한다.</p>\n<p><br/><strong>4) Cycle consistency loss</strong></p>\n<p>특정 domain으로 변환된 이미지를 원래 이미지의 s를 적용하면 원래 이미지와 같은 픽셀값을 가진 이미지로 돌아오는지 확인한다. </p>\n<p><br/><strong>5) Full objective</strong></p>\n<p>최종 손실함수는 아래와 같다. 이때 이때 λ는 하이퍼파라미터로 adversarial loss를 기준으로 각 loss의 중요도를 반영해 정해진다.</p>\n<p><span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto;  max-width: 719px;\">\n      <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 10.333333333333334%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAACCAIAAADXZGvcAAAACXBIWXMAAAsSAAALEgHS3X78AAAAeklEQVQI1w3ByxKCIBQAUP//P/qG2rZrYpObsnTGcLhg6MirRC4BdU6FiO7v7Z2in2GHYd1WF3Mx9CbO+5RSxBDj91gf5CK830rJdQOnS59zrjgAIeT+aLu2MUrw4Wq11MZKASOjM1AMYZokCEZZr61WSo1yflLGX8sPPzRtfzxxwt0AAAAASUVORK5CYII=&apos;); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"final\" title=\"final\" src=\"/static/3728ce2ee8a0885359fc0de14c4d6347/073e9/final.png\" srcset=\"/static/3728ce2ee8a0885359fc0de14c4d6347/5a46d/final.png 300w,\n/static/3728ce2ee8a0885359fc0de14c4d6347/0a47e/final.png 600w,\n/static/3728ce2ee8a0885359fc0de14c4d6347/073e9/final.png 719w\" sizes=\"(max-width: 719px) 100vw, 719px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\">\n    </span><br/></p>\n<h2 id=\"4-experiments\" style=\"position:relative;\"><a href=\"#4-experiments\" aria-label=\"4 experiments permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>4. Experiments</h2>\n<p><span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto;  max-width: 562px;\">\n      <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 54.333333333333336%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAIAAADwazoUAAAACXBIWXMAAAsSAAALEgHS3X78AAABw0lEQVQozz2RC4+iQBCE/f9/a93E3Y28QRiGYYaXTwRURGNy3sfmcp1Apmeqqqu7F8/n83q9iiSJ43gYBtLpPt3H8Xa7jePIE4eyLPI8n6Zp6Hutte/7bXt+vV6L2/WqlPpcfnwsl57vB0QY5JU67A9EVVXb7dZ1Xcd1SY0xUkrKcEB6gXZZlr7nrtdr1/Usa23ZtuM5Rpv7/d513TD0QFWegz6dTtP0IPq+53VxuVx2ux1mbGsthEBYJMK2LORFKrQxALIs+09Gq+vOiP6ShwGm53nfPz/8bdv+/vrCZ1EUTd2APh6PNExrEHAuZWpZ1uFw/Ge7bdsk3tiOHQux2Wz8wHccl2LMj1dABb7L8vGYZhdSrlYrhol5yJcgDOtmi+Q8rcCPoohCOldam6auaST53UVVVvv9PgwDADTYnruZPE8Pk03DVVEYmUo8M2SUuMRLIkRd11rnOZ/WvILc7vYLNkpHaZoiAbosK0ySGlPMw5sjVZmKk4Rts0qjdVkUpO35DHnEk8zoJWPODBYmGSSVyTCMKJeKJIyiqq5R14bKqMuZjO0Zp+biLJz6+ORPOjOVcj2Pe9DIT4/n+/3+Q7zn+AugmkaDUxMdiwAAAABJRU5ErkJggg==&apos;); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"exp\" title=\"exp\" src=\"/static/855dce015f382a855ea2af8327596db8/6e88f/exp.png\" srcset=\"/static/855dce015f382a855ea2af8327596db8/5a46d/exp.png 300w,\n/static/855dce015f382a855ea2af8327596db8/6e88f/exp.png 562w\" sizes=\"(max-width: 562px) 100vw, 562px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\">\n    </span><br/></p>\n<p>논문의 basic setup은 StarGAN으로, WGAN-GP, ACGAN discriminator, depth-wise concatenation을 적용하고, Dataset은 CelebA-HQ와 AFHQ를 사용한다.<br>\nmetric으로는 Frechet Inception Distance (FID), Learned Perceptual Image Patch Similarity (LPIPS) 을 사용하는데, FID는 실제 이미지와 생성된 이미지의 특징 벡터간의 거리를 계산한 값이고, 수치가 낮을수록 생성된 이미지와 실제 이미지가 유사함을 나타낸다. LPIPS는 이미지 패치 유사성을 나타내며 생성된 이미지의 품질과 다양성을 평가한다.\nmethod를 거쳐갈수록 수치가 낮아져 실제 이미지와 유사해 진다는 결과가 나타난다.</p>\n<h2 id=\"5-conclusion\" style=\"position:relative;\"><a href=\"#5-conclusion\" aria-label=\"5 conclusion permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>5. Conclusion</h2>\n<p>StarGAN v2는 <span style=\"color:red\">다양한 domain을 한번에 transfer를 할 수 있으며, 특정 domain에 대해 여러가지의 style transfer가 가능</span>하다. StarGAN v2는 하나의 모델로 두가지 특성을 모두 만족하며 다른 GAN모델 보다 우수한 성능을 보인다.</p>\n<h2 id=\"6-reference\" style=\"position:relative;\"><a href=\"#6-reference\" aria-label=\"6 reference permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>6. Reference</h2>\n<blockquote>\n<p><em>1. <a href=\"https://github.com/clovaai/stargan-v2\">https://github.com/clovaai/stargan-v2</a></em><br>\n<em>2. <a href=\"https://truman.tistory.com/246?category=854798\">https://truman.tistory.com/246?category=854798</a></em></p>\n</blockquote>","frontmatter":{"title":"[논문리뷰] StarGAN v2","date":"March 02, 2022"}}},"pageContext":{"slug":"/논문뽀개기/StarGANv2/","previous":{"fields":{"slug":"/Data Structure/정렬/"},"frontmatter":{"title":"정렬알고리즘 정리(Bubble, Selection, Insertion, Merge, Quick)"}},"next":{"fields":{"slug":"/ETC/miniforge/"},"frontmatter":{"title":"Mac M1 Miniforge,Tensorflow 설치하기"}}}},"staticQueryHashes":["2486386679","3128451518"]}