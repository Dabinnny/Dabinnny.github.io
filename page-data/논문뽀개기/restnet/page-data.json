{"componentChunkName":"component---src-templates-blog-post-js","path":"/논문뽀개기/restnet/","result":{"data":{"site":{"siteMetadata":{"title":"DABI_devlog","author":"[DABIN SEO]","siteUrl":"https://Dabinnny.github.io","comment":{"disqusShortName":"","utterances":"Dabinnny/Dabinnny.github.io"},"sponsor":{"buyMeACoffeeId":""}}},"markdownRemark":{"id":"05ef0305-3fd2-53e9-bd58-4b74618dafa6","excerpt":"📖 ResNet : A Deep Residual Learning Framework 이 글은 ‘ResNet : Deep Residual Learning for Image Recognition’ 논문을 바탕으로 합니다. 1. Introduction 본 논문은 일반적으로 layer가 깊어지면 깊어질수록 높은 성능을 보일것이다 라는 일반적인 견해의 문제점을 해결한다.  왼쪽그림이 일반적인 CNN모델이고 오른쪽인 Resnet의 결과이다.   CNN네트워크를 확인해보면 레이어가 깊은 모델이 error…","html":"<h1 id=\"-resnet--a-deep-residual-learning-framework\" style=\"position:relative;\"><a href=\"#-resnet--a-deep-residual-learning-framework\" aria-label=\" resnet  a deep residual learning framework permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>📖 ResNet : A Deep Residual Learning Framework</h1>\n<br/>  \n<blockquote>\n<p>이 글은 <em>‘ResNet : Deep Residual Learning for Image Recognition’</em> 논문을 바탕으로 합니다.</p>\n</blockquote>\n<br/>\n<h2 id=\"1-introduction\" style=\"position:relative;\"><a href=\"#1-introduction\" aria-label=\"1 introduction permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>1. Introduction</h2>\n<div align=\"center\"> <img src=\"https://user-images.githubusercontent.com/90162819/159157933-c768a743-5510-4311-9294-21bbe185cedf.png\" width=\"700\"></div>\n<p>본 논문은 일반적으로 layer가 깊어지면 깊어질수록 높은 성능을 보일것이다 라는 일반적인 견해의 문제점을 해결한다.<br>\n왼쪽그림이 일반적인 CNN모델이고 오른쪽인 Resnet의 결과이다.<br>\nCNN네트워크를 확인해보면 레이어가 깊은 모델이 error가 높은것을 확인할 수 있다. 즉 성능이 더 안좋아진것이다.  </p>\n<p>결론 먼저 얘기하자면 단순히 layer를 깊게 쌓는것만으로는 성능을 높일 수 없고 ResNet에서는 <code class=\"language-text\">Residual Learning(잔여학습)</code>으로 layer를 깊게 쌓으면서도 성능을 높인다는 것을 입증하고 있다.<br>\n<code class=\"language-text\">Residual Learning(잔여학습)</code>에 대해서는 아래에서 자세히 알아보자.  </p>\n<br/>\n<h2 id=\"1-residual-learning\" style=\"position:relative;\"><a href=\"#1-residual-learning\" aria-label=\"1 residual learning permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>1. Residual Learning</h2>\n<p>자, 그럼 layer가 너무 깊어지면 왜 오히려 성능이 떨어지는 경우가 발생할까?  </p>\n<p>직관적으로 Vanishing/Exploding gradients가 발생하기 때문이다.<br>\n이 문제들은 Normalization으로 어느정도 해결할 수 있지만 온전한 해결이 되진 못하기 때문에 깊은 네트워크를 가진 모델을<br>\n학습시키는것은 상당히 까다롭다.  </p>\n  <br/>\n<p>깊은 네트워크는 단순히 Overfitting의 문제가 아니라 정확도가 급속하게 감소하는 Degradation(성능저하) 문제가<br>\n발생하는데, 이는 test error만이 아닌, training error도 함께 높아진것에서 확인할 수 있다.<br>\n이는 최적화 되는 방식이 다르기 때문에 최적화가 쉽지 않다는것을 보여준다.</p>\n<br/>\n<p><code class=\"language-text\">Residual Learning(잔여학습)</code>은 학습을 하고자 하는 mapping H(x)에 대해서 optimization을 낮춰준다.<br>\n이 말은,  </p>\n<ul>\n<li>학습을 하고자 하는 mapping H(x)를 곧바로 학습하지 않고 학습하기 쉬운 F(x)를 학습시키는 것이다.</li>\n<li>정말 간단하게 말하면, input 값을 결과값에 더해주는것만 추가가 되는 구조이다. </li>\n<li>앞선 layer에서 학습된 정보를 그대로 가져올 수 있기때문에 F(x)만 학습하면 되니 더 쉽다는 것이다.  </li>\n</ul>\n<br/>\n<p>아래의 그림을 살펴보자.  </p>\n<div align=\"center\"> <img src=\"https://user-images.githubusercontent.com/90162819/159157813-8de8996e-d886-44bb-9521-e29cd1b8e61f.png\" width=\"600\"></div>\n<br/>\n<p>기존 neural network구조와 ResNet의 구조이다.<br>\n기존 네트워크는 input값을 받으면 convolution layer와 activation function을 거쳐 H(x)를 출력하고<br>\n이 H(x)를 최소화 시키는것이 학습의 목표라면, ResNet은 F(x) = H(x) - x를 최소화시키는것으로 재정의 하고<br>\n<code class=\"language-text\">Short Connection</code>에 의해 구현가능하다. </p>\n<blockquote>\n<p><em>Short Connection : layer의 입력을 출력값에 그대로 더해주어 추가적인 파라미터와 복잡도가 늘어나지 않는 것</em>  </p>\n</blockquote>\n<br/>\n<p>H(x)가 x가 되도록 학습하는것보다 residual인 F(x)가 0으로 되도록 학습하는 것이 최적화가 쉽다는 것이며,\nF(x) + x 형태의 Short Connection은 Identity mapping을 추가함으로써 학습이 쉬워지게 한다. </p>\n<br/>\n<br/>\n<div align=\"center\"> <img src=\"https://user-images.githubusercontent.com/90162819/159157864-0a0b2d2d-7f50-496f-ad58-8e85960b7638.png\"></div>\n<p>여기서 x는 input, y는 output vectors F(x,{Wi})는 학습될 residual mapping을 의미한다.<br>\n두개의 weight layer와 ReLU를 거치기에 F=W2σ(W1x)의 수식으로 나타낼 수 있다. bias는 생략한다.  </p>\n<br/>\n<div align=\"center\"> <img src=\"https://user-images.githubusercontent.com/90162819/159157866-d6f5985b-c852-468c-b254-299863bf5223.png\"></div>\n<p>input과 output의 차원이 다를경우에는 linear projection인 Ws를 곱하여 차원을 같게 만들 수 있다.<br>\n여기서 Ws는 차원을 매칭 시켜줄 때에만 사용한다.  </p>\n<h2 id=\"3-network-architectures\" style=\"position:relative;\"><a href=\"#3-network-architectures\" aria-label=\"3 network architectures permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>3. Network Architectures</h2>\n<div align=\"center\"> <img src=\"https://t1.daumcdn.net/cfile/tistory/9931D4425CB8A11F1E\"></div>\n<ol>\n<li><strong>Plain Network</strong> </li>\n</ol>\n<p>baseline 모델로 VGGNet에 기반하지만 VGGNet보다 적은 필터와 복잡성을 가진다.  특징으로는,</p>\n<ul>\n<li>3 x 3의 conv layer를 가지고 각 layer들은 같은 크기의 output feature map과 같은 수의 filter를 갖는다. </li>\n<li>downsampling을 하기 위해서는 feature map size는 반으로 줄어들고, layer당 filter의 수는 2배로 늘려 time-complexity를 유지한다.</li>\n</ul>\n<br/>\n<ol start=\"2\">\n<li><strong>Residual Network</strong></li>\n</ol>\n<p>Plain Network에 기반해서 Shortcut connection을 추가하여 구성한다.  </p>\n<ul>\n<li>이때 dimension이 증가했을때는 zero padding을 적용해서 차원을 키워줘야 하고,</li>\n<li>1x1 conv을 사용하여 projection shortcut을 적용해주어야 한다.  </li>\n</ul>\n<br/>\n<div align=\"center\"> <img src=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FRRHwz%2FbtqS29j0gWf%2FDwx6D2904Gb0wJbIk5esbK%2Fimg.png\" width=\"500\"></div>\n<h2 id=\"4-implementation\" style=\"position:relative;\"><a href=\"#4-implementation\" aria-label=\"4 implementation permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>4. Implementation</h2>\n<p>모델 구현은 다음과 같이 진행한다.  </p>\n<ul>\n<li>image resize: 224 * 224 로 random하게 crop</li>\n<li>Batch normalization 적용</li>\n<li>Initialize Weights : He 초기화</li>\n<li>Optimizer : SGD</li>\n<li>mini batch: 256</li>\n<li>Learning rate : 0.1 </li>\n<li>Iteration: 60 * 10^4</li>\n<li>weight decay: 0.0001</li>\n<li>Decay &#x26; Momentum : 0.0001, 0.9</li>\n<li>No dropout  </li>\n</ul>\n<h2 id=\"5-experiments\" style=\"position:relative;\"><a href=\"#5-experiments\" aria-label=\"5 experiments permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>5. Experiments</h2>\n<div align=\"center\"> <img src=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FnMtLu%2FbtqS6YIJkSe%2F95gQHZ4BygKZwgEH0e8lEk%2Fimg.png\"></div> \n<div align=\"center\"> <img src=\"https://t1.daumcdn.net/cfile/tistory/9933913E5CB8A11F2A\" width=\"400\"></div>\n<p>Data는 ImageNet을 사용한다.  </p>\n<ol>\n<li><strong>Plain Network</strong> </li>\n</ol>\n<p>더 깊은 plain model에서 validation error가 나타난다. training / validation error 모두를 비교한 결과, 34 layer plain 모델에서 training error도 높았기 때문에 degradation 문제가 있다고 판단된다.  </p>\n<br/>\n<ol start=\"2\">\n<li><strong>Residual Network</strong></li>\n</ol>\n<p>실험에선 위 표와같은 구조를 사용하였다.</p>\n<ul>\n<li>18-layer ResNet 보다 34-layer ResNet이 2.8% 성능이 높다.<br>\n34-layer ResNet에서 상당히 낮은 training error를 보였고, 이에 따라 validation 성능 또한 높아졌다.<br>\n이는 degradation 문제가 잘 해결되었으며, depth가 증가하더라도 좋은 정확도를 얻을 수 있음을 의미한다.  </li>\n</ul>\n  <br/>\n<ul>\n<li>34-layer plain net에 비교하여 34-layer ResNet은 3.5%나 더 낮은 error를 보인다.<br>\n이 비교는 deep한 system의 residual을 학습하는 것이 더 효율적이라는 것을 의미한다.  </li>\n</ul>\n  <br/>  \n<ul>\n<li>ResNet은 같은 상황에서 더 빨리 수렴한다. 18-layer ResNet과 plain net을 비교했을 때 성능이 거의 유사했지만,<br>\n18-layer의 ResNet이 더 빨리 수렴하였다. 즉, 모델이 과도하게 깊지 않은 경우 (18-layer), 현재의 SGD Solver는<br>\n여전히 plain net에서도 좋은 solution을 찾을 수 있지만, ResNet은 더 쉽게 최적화를 수행한다.  </li>\n</ul>\n<h2 id=\"6-conclusion\" style=\"position:relative;\"><a href=\"#6-conclusion\" aria-label=\"6 conclusion permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>6. Conclusion</h2>\n<ul>\n<li>ResNet은 단순하게 Layer를 쌓는 형태는 identity mapping에 적합하지 않으므로(=Degradation 문제 발생), Residual Mapping을 통해 Degradation 문제를 해결한다.  </li>\n<li>ResNet은 PlainNet보다 최적화가 용이하고, Depth가 깊어져도 성능 향상이 보증된다.</li>\n<li>\n<p>이 포스팅에서는 적진 않았지만 </p>\n<ul>\n<li>앙상블을 적용했을 경우 Error rate은 더 낮아진다.</li>\n<li>ImageNet 데이터에 국한된것이 아닌 다른 데이터들에도 범용적으로 잘 적용된다.</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"7-reference\" style=\"position:relative;\"><a href=\"#7-reference\" aria-label=\"7 reference permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>7. Reference</h2>\n<blockquote>\n<p>*1. <a href=\"https://arxiv.org/abs/1512.03385\">https://arxiv.org/abs/1512.03385</a><br>\n*2. <a href=\"https://ropiens.tistory.com/32\">https://ropiens.tistory.com/32</a></p>\n</blockquote>","frontmatter":{"title":"[논문리뷰] ResNet","date":"December 04, 2021"}}},"pageContext":{"slug":"/논문뽀개기/restnet/","previous":{"fields":{"slug":"/TroubleShooting/runtime/"},"frontmatter":{"title":"Colab 런타임 끊김 방지"}},"next":{"fields":{"slug":"/DeepLearning/데이터증강/"},"frontmatter":{"title":"Data Augmentation(데이터 증강) 파헤치기"}}}},"staticQueryHashes":["2486386679","3128451518"]}